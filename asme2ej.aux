\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Dataset di riferimento}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Architettura del modulo per il retrieve di tweet dallo stream. Vengono scartate citt\'a non USA e vengono associati agli stati alle citt\'a non correttamente formattate.}}{1}}
\newlabel{gazproc.ps}{{1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Problematiche iniziali}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Descrizione dei flussi di esecuzione}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Prefiltraggio del dump di Wikipedia}}{2}}
\newlabel{step1.ps}{{2}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Implementazione di Lector}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Rimozione rumore e frasi non relazionali}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Associazione di frasi e relazioni senza stopping e generalizzazione}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Misurazione della forza di un'associazione entit\'a-frase}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Join tra le triple e i fatti}}{3}}
\newlabel{step1.ps}{{3}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Estrazione di nuovi fatti e validazione}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Frasi pi\'u ricorrenti per la relazione \textit  {graduatedFrom}}}{4}}
\newlabel{step1.ps}{{4}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Variazione del numero di fatti estratti al variare dei vincoli}}{4}}
\newlabel{table_ASME}{{1}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Generalizzazione e stopping}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Fatti estratti e fatti validati con il processo di generalizzazione e con il processo ibrido generalizzazione e stopping}}{5}}
\newlabel{table_ASME}{{2}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Normalizzazione di frasi lista}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.6.1}Prefiltraggio di frasi}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.6.2}Valutazione del prefiltro}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Processo di prefiltraggio dellle frasi lista}}{6}}
\newlabel{step1.ps}{{5}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.6.3}Utilizzo di Stanford NLP Core}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Valutazione dei fatti estratti}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Nella figura vengono mostrate le dipendenze individuate tramite la libreria di Stanford. Gli nmod rilevanti, cerchiati in verde, sono quelli che presentano diversi dependent. nmod:of viene quindi scartato in quanto presenta una sola dependent.}}{8}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces In tabella i risultati ottenuti applicando Lector su \textbf  {FreeBase}}}{8}}
\newlabel{table_ASME}{{3}{8}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces In tabella i risultati ottenuti applicando Lector su \textbf  {YAGO} senza generalizzazione e stopping}}{8}}
\newlabel{table_ASME}{{4}{8}}
